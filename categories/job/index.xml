<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Job on Grey Times</title>
    <link>http://kangkona.github.io/categories/job/</link>
    <description>Recent content in Job on Grey Times</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 02 Nov 2014 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://kangkona.github.io/categories/job/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Storm集群的安装与配置</title>
      <link>http://kangkona.github.io/posts/storm-cluster-install-config/</link>
      <pubDate>Sun, 02 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>http://kangkona.github.io/posts/storm-cluster-install-config/</guid>
      <description>

&lt;h2 id=&#34;1-infrastructure:cb311eb8dc04c7f9620c5e97632331c7&#34;&gt;1. Infrastructure&lt;/h2&gt;

&lt;p&gt;3台流处理Server
- CPU : 3 Core
- Memory : 3G
- Disk : 300G
- OS : Ubuntu Server 12.04 64bit&lt;/p&gt;

&lt;h2 id=&#34;2-depended-software:cb311eb8dc04c7f9620c5e97632331c7&#34;&gt;2. Depended Software&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;built-essential&lt;/li&gt;
&lt;li&gt;Python 2.7&lt;/li&gt;
&lt;li&gt;Java 1.7.0_71(最低要求1.6)&lt;/li&gt;
&lt;li&gt;Zookeeeper 3.4.6&lt;/li&gt;
&lt;li&gt;ZeroMQ 4.0.5&lt;/li&gt;
&lt;li&gt;jzmq github-master&lt;/li&gt;
&lt;li&gt;Storm 0.9.1-incubating&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;3-install-config:cb311eb8dc04c7f9620c5e97632331c7&#34;&gt;3. Install &amp;amp;&amp;amp; Config&lt;/h2&gt;

&lt;p&gt;几乎所有软件对集群中的机器来说，安装过程都是完全一致的，所有没有必要在每台机器重复安装过程，可以使用Puppet或者Docker这些工具来提高效率。但由于操作的集群网络环境受限，最终利用Xshell可以一次向多个会话发送命令的功能，做到了完全同步的安装和配置。&lt;/p&gt;

&lt;h3 id=&#34;3-1-修改-etc-hosts:cb311eb8dc04c7f9620c5e97632331c7&#34;&gt;3.1 修改/etc/hosts&lt;/h3&gt;

&lt;p&gt;使用名称来代表机器会带来很多方便，在/etc/hosts中追加如下内容：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;172.21.1.168	master
172.21.1.169	node1
172.21.1.170	node2
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-2-build-essential:cb311eb8dc04c7f9620c5e97632331c7&#34;&gt;3.2 build-essential&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://packages.ubuntu.com/lucid/amd64/build-essential/filelist&#34;&gt;build-essential&lt;/a&gt;作用是提供编译程序必须软件包的列表信息, 编译程序有了这个软件包, 才知道 头文件和库函数的位置，还会下载依赖的软件包，组成一个基本的开发环境&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  $ sudo apt-get install build-essential
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-3-安装jdk:cb311eb8dc04c7f9620c5e97632331c7&#34;&gt;3.3 安装JDK&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ tar zxvf jdk-7u71-linux-x86.tar.gz
# mv jdk1.7.0_71 /usr/lib/jvm
# sudo vim /etc/profile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;追加内容：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export JAVA_HOME=/usr/lib/jvm/jdk1.7.0_71
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:${JRE_HOME}/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$source /etc/profile
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-4-安装zookeeper-3-4-6:cb311eb8dc04c7f9620c5e97632331c7&#34;&gt;3.4 安装Zookeeper 3.4.6&lt;/h3&gt;

&lt;p&gt;详细内容可以参考 &lt;a href=&#34;http://www.iteblog.com/archives/904&#34;&gt;Zookeeper 3.4.5分布式安装手册&lt;/a&gt; 这篇文章， 这里简要描述：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ tar -zxvf zookeeper-3.4.6.tar.gz
$ cd zookeeper-3.4.6/conf/
$ cp zoo_sample.cfg zoo.cfg
$ vim zoo.cfg
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;将里面的默认配置修改为如下（具体配置可以根据你机器来定）：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;tickTime=2000
# The number of ticks that the initial
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just
# example sakes.
dataDir=/logs/zookeeper
# the port at which the clients will connect
clientPort=2181

server.1 = master:2888:3888
server.2 = node1:2888:3888
server.3 = node2:2888:3888
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;在刚刚zoo.cfg文件中dataDir属性指定的目录（本文中为/logs/zookeeper）下创建一个myid，在里面添加你指定的server编号，因为这台机器是master，而zoo.cfg中master编号为1(server.1=master:2888:3888)，所以myid内容只需要为1即可。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir -p /logs/zookeeper
$ echo 1   &amp;gt; /logs/zookeeper/myid 
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;这样就在master机器上配置好Zookeeper，接下来只需要将master配置好的Zookeeper整个目录打包分发到node1、node2机器中，解压到安装位置。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;不要忘记在node1的/logs/zookeeper/myid文件中添加2。node2的/logs/zookeeper/myid文件中添加3。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;将每个机器的zookeeper的路径添加到Path
在/etc/profile追加如下内容：&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;# zookeeper
export ZOOKEEPER_HOME=/packages/zookeeper-3.4.6
export PATH=${ZOOKEEPER_HOME}/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;不要忘记在三台机器 &lt;code&gt;source /etc/profile&lt;/code&gt; 使之生效。&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;分别在master、node1、node2机器上启动Zookeeper相关服务：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ZOOKEEPER_HOME/bin/zkServer.sh start
JMX enabled by default
Using config: /home/wyp/Downloads/zookeeper-3.4.5/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;测试Zookeeper是否安装成功：
参见 &lt;a href=&#34;http://www.iteblog.com/archives/904&#34;&gt;Zookeeper 3.4.5分布式安装手册&lt;/a&gt; 第7点 。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3-5-安装zmq:cb311eb8dc04c7f9620c5e97632331c7&#34;&gt;3.5 安装ZMQ&lt;/h3&gt;

&lt;p&gt;默认安装在/usr/local/lib位置，后面会比较省劲：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tar -xzf zeromq-4.0.5.tar.gz
$ cd zeromq-4.0.5
$ ./configure
$ make
$ sudo make install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-6-安装-jzmq:cb311eb8dc04c7f9620c5e97632331c7&#34;&gt;3.6 安装 jzmq&lt;/h3&gt;

&lt;p&gt;最开始装&lt;a href=&#34;https://github.com/nathanmarz/jzmq&#34;&gt;nathanmarz&lt;/a&gt;的分支，一直无法make，最后下载了zeromq的&lt;a href=&#34;https://github.com/zeromq/jzmq&#34;&gt;master&lt;/a&gt;分支。  make过程中提示安装libtool, pkg-config, autoconf几个工具:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo apt-get install libtool pkg-config autoconf
$ git clone https://github.com/zeromq/jzmq
$ cd jzmq
$ ./autogen.sh
$ ./configure
$ make
$ sudo make install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-7-storm-install-config:cb311eb8dc04c7f9620c5e97632331c7&#34;&gt;3.7 Storm install &amp;amp;&amp;amp; config&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;安装之前的调研&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在官网下载了storm-0.9.1-incubating 版本解压到安装位置。 该版本的一大亮点是采用了Netty做消息传输层，在以前的版本里，Storm只能依赖ZeroMQ做消息的传输，但其实并不适合,  &lt;a href=&#34;http://www.cnblogs.com/alephsoul-alephsoul/p/3467651.html&#34;&gt;理由&lt;/a&gt;：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ZeroMQ是一个本地化的消息库，它过度依赖操作系统环境；&lt;/li&gt;
&lt;li&gt;安装起来比较麻烦；(有了Netty可以不要ZeroMQ和jzmq)&lt;/li&gt;
&lt;li&gt;ZeroMQ的稳定性在不同版本之间差异巨大，并且目前只有2.1.7版本的ZeroMQ能与Storm协调的工作(写文档才注意到这句话。。。后面需要测试一下)。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;引入Netty的原因是：
  - 平台隔离，Netty是一个纯Java实现的消息队列，可以帮助Storm实现更好的跨平台特性，同时基于JVM的实现可以让我们对消息有更好的控制；
  - 高性能，Netty的性能要比ZeroMQ快两倍左右，&lt;a href=&#34;http://yahooeng.tumblr.com/post/64758709722/making-storm-fly-with-netty&#34;&gt;让Storm飞&lt;/a&gt; 专门比较了ZeroMQ和Netty的性能。
  -  安全性认证，使得我们将来要做的 worker 进程之间的认证授权机制成为可能。&lt;/p&gt;

&lt;p&gt;主要参考&lt;a href=&#34;http://www.cnblogs.com/panfeng412/archive/2012/11/30/how-to-install-and-deploy-storm-cluster.html&#34;&gt;Storm集群安装部署步骤【详细版】&lt;/a&gt; 和其他集群的经验对conf/storm.yaml进行如下配置：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;storm.zookeeper.servers: Storm集群使用的Zookeeper集群地址，其格式如下：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;storm.zookeeper.servers:
     - &amp;quot;172.21.1.168&amp;quot;
     - &amp;quot;172.21.1.169&amp;quot;
     - &amp;quot;172.21.1.170&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果Zookeeper集群使用的不是默认端口，那么还需要storm.zookeeper.port选项。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;storm.local.dir: Nimbus和Supervisor进程用于存储少量状态，如jars、confs等的本地磁盘目录，需要提前创建该目录并给以足够的访问权限。然后在storm.yaml中配置该目录，如：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;storm.local.dir: &amp;quot;/logs/storm/workdir&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;java.library.path: Storm使用的本地库(ZMQ和JZMQ)加载路径，默认为&amp;rdquo;/usr/local/lib:/opt/local/lib:/usr/lib&amp;rdquo;，一般来说ZMQ和JZMQ默认安装在/usr/local/lib 下，因此不需要配置即可。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;nimbus.host: Storm集群Nimbus机器地址，各个Supervisor工作节点需要知道哪个机器是Nimbus，以便下载Topologies的jars、confs等文件，如：&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;nimbus.host: &amp;quot;172.21.1.168&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;supervisor.slots.ports: 对于每个Supervisor工作节点，需要配置该工作节点可以运行的worker数量。每个worker占用一个单独的端口用于接收消息，该配置选项即用于定义哪些端口是可被worker使用的。默认情况下，每个节点上可运行4个workers，分别在6700、6701、6702和6703端口，我配置了80个：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;supervisor.slots.ports:
    - 6700
    - 6701
    - 6702
    - 6703
     ......
    - 6780
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;storm UI端口&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;ui.port: 8088
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;如果要在Storm里使用Netty做传输层，只需要简单的把下面的内容加入到storm.yaml中，并根据你的实际情况调整参数即可：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;storm.messaging.transport: &amp;quot;backtype.storm.messaging.netty.Context&amp;quot;
storm.messaging.netty.server_worker_threads: 1
storm.messaging.netty.client_worker_threads: 1
storm.messaging.netty.buffer_size: 5242880
storm.messaging.netty.max_retries: 100
storm.messaging.netty.max_wait_ms: 1000
storm.messaging.netty.min_wait_ms: 100
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;为了方便使用，可以将Storm位置加入到系统环境变量中&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在/etc/profile追加如下内容：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Storm
export STORM_HOME=/packages/zookeeper-3.4.6
export PATH=${STORM_HOME}/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;不要忘记在三台机器 &lt;code&gt;source /etc/profile&lt;/code&gt; 使之生效。&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;启动Storm各个后台进程&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最后一步，启动Storm的所有后台进程。和Zookeeper一样，Storm也是快速失败（fail-fast)的系统，这样Storm才能在任意时刻被停止，并且当进程重启后被正确地恢复执行。这也是为什么Storm不在进程内保存状态的原因，即使Nimbus或    Supervisors被重启，运行中的Topologies不会受到影响。&lt;/p&gt;

&lt;p&gt;以下是启动Storm各个后台进程的方式：
  - Nimbus: 在Storm主控节点上运行&amp;rdquo;bin/storm nimbus &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;&amp;ldquo;启动Nimbus后台程序，并放到后台执行；
  - Supervisor: 在Storm各个工作节点上运行&amp;rdquo;bin/storm supervisor &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;&amp;ldquo;启动Supervisor后台程序，并放到后台执行；
  - UI: 在Storm主控节点上运行&amp;rdquo;bin/storm ui &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;&amp;ldquo;启动UI后台程序，并放到后台执行，启动后可以通过http://{nimbus host}:8080观察集群的worker资源使用情况、Topologies的运行状态等信息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意事项&lt;/strong&gt;：
  - Storm后台进程被启动后，将在Storm安装部署目录下的logs/子目录下生成各个进程的日志文件。
  - 经测试，Storm UI必须和Storm Nimbus部署在同一台机器上，否则UI无法正常工作，因为UI进程会检查本机是否存在Nimbus链接。&lt;/p&gt;

&lt;p&gt;至此，Storm集群已经部署、配置完毕，可以向集群提交拓扑运行了。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;向集群提交任务&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;启动Storm Topology：&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;storm jar allmycode.jar org.me.MyTopology arg1 arg2 arg3&lt;/code&gt;
 - 停止Storm Topology：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;storm kill {toponame}&lt;/code&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>人性化排序</title>
      <link>http://kangkona.github.io/posts/friendly-sort/</link>
      <pubDate>Mon, 27 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>http://kangkona.github.io/posts/friendly-sort/</guid>
      <description>&lt;p&gt;对于大部分产品来说，搜索功能是必不可少的。有搜索的地方，就有排序。对文本信息的排序没有数值排序来的那么直观，对搜索到的信息，通常的展示策略有三种：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    1. 按自然顺序排列；
    2. 按相似度由高至低排列；
    3. 按信息的活性(热度)进行排列。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然，最糟糕也最常见的是下面这种方式：完全不做任何排序。&lt;/p&gt;

&lt;p&gt;最近碰到的一个应用场景让我对此进行了反思。我们的实时公交查询系统为其他App开发者提供了这样的一个API：根据用户的搜索内容返回线路名称。现在不妨假设用户输入了一个 &amp;ldquo;1&amp;rdquo;，后台进行查询，找到所有与 &amp;ldquo;1&amp;rdquo; 有关的线路，最开始我们的输出是无序的:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;               81,  17, 201路， 快线1号, 11, 1路, 168 , 高快巴士1号线 ....
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果竟然返回了221个与1有关的线路，这样的展示结果显然是会让用户骂人的。后来决定先返回所有 &amp;ldquo;1&amp;rdquo; 开头的线路，其余自然排序:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;              11, 17, 168, 1路，201路， 81, 高快巴士1号线，快线1号 ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这次结果好了很多，但是1路竟然排在168后面，仍然会让人不爽，所以按照相似度进行排序:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;              11，17，81，1路，168，201路，.... 快线1号，高快巴士1号线
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这次达到了预想的效果，但把快线1号，高快巴士1号线这样比较难记，难输入的线路放到了最后，实际上用户如果只输入 &amp;ldquo;1&amp;rdquo; 进行查询，很可能要找的就是 “快线1号” 或者 “高快巴士1号线”，所以把这种输入成本高的线路挪到了前面:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;              11, 17, 1路，168，快线1号，高快巴士1号线，201路，81 ....
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实现代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Java&#34;&gt;		Arrays.sort(sortedLineNames, new Comparator&amp;lt;Object&amp;gt;(){  
            @Override  
            public int compare(Object b1, Object b2) {  
            	String s1 = (String)b1;
            	String s2 = (String)b2;
            	
            	if (s1.startsWith(searchString) &amp;amp;&amp;amp; !s2.startsWith(searchString)) {
            		return -1;
            	} 
            	else if(!s1.startsWith(searchString) &amp;amp;&amp;amp; s2.startsWith(searchString)) {
            		return 1;
            	} 
            	else if (! s1.startsWith(searchString) &amp;amp;&amp;amp; !s2.startsWith(searchString)) {
            	       return s2.compareTo(s1);
            	}
            	else {
            	       return s1.compareTo(s2);
            	}
            }             
        });                                                                            
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然，Java 8引入lambda之后，可以简写为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;       Arrays.sort(sortedLineNames, 
                   (s1, s2) -&amp;gt;  
                     s1.startsWith(searchString) &amp;amp;&amp;amp; !s2.startsWith(searchString) ? -1 :
                    !s1.startsWith(searchString) &amp;amp;&amp;amp;  s2.startsWith(searchString) ?  1 :
                    !s1.startsWith(searchString) &amp;amp;&amp;amp; !s2.startsWith(searchString) ?  s2.compareTo(s1) : 
                     s1.compareTo(s2));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在多数情况下，这些策略已经可以组合出不错的效果了，但这就足够了么？ 用户搜索的目的是希望找到对自己有价值的信息，而排序最终是为了讨好用户：在信息呈现之前，猜测一下用户的心理，认为用户最想要什么，就把什么放在前面，让用户用最少的时间成本获取最有价值的信息。所以为了更懂用户，可能还需要对日志进行分析，统计每条线路的搜索频率，得出线路的活跃程度，每次尽可能把活性比较大的线路放置在返回结果的前面。更进一步，可以看看线路活性的分布情况和规律，得出更有指导性的结论。&lt;/p&gt;

&lt;p&gt;写到这里，突然感觉排序分明就是一种人工智能的东东，这也无怪乎那些做搜索的公司都铆足了劲儿搞深度学习。 在这样一个时代，不懂人心估计就得死吧。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>借力数据结构</title>
      <link>http://kangkona.github.io/posts/data-struct-powerful/</link>
      <pubDate>Thu, 18 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>http://kangkona.github.io/posts/data-struct-powerful/</guid>
      <description>

&lt;p&gt;做实时公交查询服务时，最重要的能够实时跟踪每一辆车的时空信息，并结合静态数据，准确刻画出一个城市每一时刻所有公交线路的状态。由于基础数据只有线路，站点这样的信息，做时间预测，位置计算便只能依赖这些信息。比较关键的思路大致如下:&lt;/p&gt;

&lt;h2 id=&#34;位置计算:d361afbdc75d323080e31fe61f4bb8f8&#34;&gt;位置计算&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;S1         S2        S3             S4                 S5            S6            S7 
                               P
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了得到P的位置，需要利用一个评价公式: 假设P到前一站距离Pre, 到后一站距离Next，两站之间距离Between，有如下公式：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   Cost =  Pre + Next - Between
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们认为使Cost取值最小的两个站即为P所在位置的前后站。&lt;/p&gt;

&lt;h2 id=&#34;时间预测:d361afbdc75d323080e31fe61f4bb8f8&#34;&gt;时间预测&lt;/h2&gt;

&lt;p&gt;比如我们要估算P到S7站点的到站时间，可以取该车次所有车最近5趟S3到S7的时间 T_AVG，所以预估时间公式为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;T_ESTIMATE = Distance(P-&amp;gt;S4-&amp;gt; ... -&amp;gt;S7) / Distance(S3-&amp;gt;S4-&amp;gt; .... -&amp;gt; S7)   *  T_AVG
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;BUT，现在通过历史数据分析，提取出了线路的轨迹信息，就是除了站点以外，还有很多有序的轨迹点可以代表线路。这些点带来的好处是： 两个站之间的轨迹是曲线(甚至环形都是很常见的)的话，如果只有站点，连出的轨迹就是一条直线段，模拟效果很差；而点多了以后，几乎就可以还原出真实的线路轨迹。&lt;/p&gt;

&lt;p&gt;在考虑如何利用这些点的时候，就碰到一个设计权衡的问题：&lt;/p&gt;

&lt;h2 id=&#34;1-不把站点插入轨迹点集里面:d361afbdc75d323080e31fe61f4bb8f8&#34;&gt;1.  不把站点插入轨迹点集里面&lt;/h2&gt;

&lt;p&gt;得到的轨迹点集合已经可以很好模拟真实情况了，而站点信息(主要是经纬度)由于是人工采集的，会存在一些偏差，把站点插入轨迹点集之后的模拟效果反而会变差(抽样发现会出现迂回的情况)。但是仍然需要记录每个轨迹点的位置信息(位于哪两站)，设计轨迹点数据结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type GeoPoint  struct {
	lat	float
	lng	float
}

type TrackPoint struct {
	GeoPoint
	preStationIndex	int  //前一站
	nextStationIndex	int  //后一站
	index	int   //在点集中的次序
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时进行位置计算，就需要用轨迹点去计算:  先算出在哪两个点之间，然后根据前后点的关系，计算出在哪两个站点之间，这时计算比较复杂，可以分成如下情况：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;前后点没有跨站&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  /**
    *    S1  p1 . . .   pre  cur  next   . .  p2  S2 . . . S3
    *  
    *  Path(S1, cur) =  Dis(cur, pre) + Σ PointDis(p1-pre) + Dis(S1, p1)
    *  Path(S2, cur) =  Dis(cur, next) + Σ PointDis(next-p2) + Dis(p2, S2)
    */
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;前后点跨站&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//    case1:  S1  . . .   pre   cur  S2   next  . . . . S3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;//     case2:  S1  &amp;hellip;   pre   S2   cur  next  &amp;hellip; . S3&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了区分这两种情况，还要利用上面的Cost函数，计算cur到底在pre-S2，还是S2-next，计算过程十分繁琐。 时间预测的计算有过之而无不及。&lt;/p&gt;

&lt;h2 id=&#34;2-把站点插入轨迹集合里面:d361afbdc75d323080e31fe61f4bb8f8&#34;&gt;2. 把站点插入轨迹集合里面&lt;/h2&gt;

&lt;p&gt;如果把站点插入轨迹集合里面，计算位置以及预测时间的过程就会简化许多，这时就需要给TrackPoint增加类型信息进行区分(将来可能会加入红绿灯，拐点等类型) :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const ( 
    Ordinary =  iota
    TurnPoint
    Station
    TrafficLight 
)

type Kind int

type TrackPoint struct {
	GeoPoint
	preStationIndex	int  //前一站
	nextStationIndex	int  //后一站
	index	int   //在点集中的次序
	kind	Kind //点类型
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于站点也是轨迹集合的一员，位置计算时就不存在是否跨站问题了，  时间预测时到两站的距离也只需要计算两部分。&lt;/p&gt;

&lt;p&gt;本来为了使轨迹信息不致于受到站点的干扰，采用了第一种设计。但实现位置计算以及时间预测时，明显感觉各种计算都要围绕站点来进行，即使轨迹序列里不加站点，在其他地方还是会受到钳制。改用第二种设计之后，很多计算就变得自然许多，简洁许多，省了很多不必要的弯路。 借用《The Design of Design》的一句话就是：
&lt;p&gt;&lt;/p&gt;
&lt;div style=&#34;background-color:black; font:bold 17px italic red;padding-left:50px&#34; &gt;
     The viewpoint is that of an engineer, focused on utility and effctiveness
      but also efficiency and elegance.&lt;/p&gt;

&lt;p&gt;&lt;/div&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Storm实时处理案例(1)</title>
      <link>http://kangkona.github.io/posts/storm-real-time-case-1/</link>
      <pubDate>Thu, 04 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>http://kangkona.github.io/posts/storm-real-time-case-1/</guid>
      <description>&lt;p&gt;在Storm里面，用水流来比作数据流真是再合适不过了。 raw数据源源不断地流向Spout,
Spout对流入的数据进行检查，如果是符合要求的数据(好比质检合格的水),则从流中截
出一个单位数据。&lt;/p&gt;

&lt;p&gt;通常会对流入的数据源定好协议，比如一个单位数据的header是FAFB, tail是EAEB：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    while( true ) {
        while( true ) {
         first = is.readByte();
         if (first == (byte)0xFA) {
            second = is.readByte();
            if (second == (byte)0xFB) {
                break;
            }
         }
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实上段代码不够严谨，比如出现0xFA0xFA0xFB&amp;hellip;这样的流，就可能会丢弃正常的流。
询问得知正文和头部是正交的, 暂时按下不表。&lt;/p&gt;

&lt;p&gt;之后对截断的流进行基础性的检查，emit出去，交给Bolt处理。&lt;/p&gt;

&lt;p&gt;Spout只管喷射出一个个截断的数据流，Bolt(螺栓)把自己拧在Spout的接口上, 对输出
的元组进行必要的处理。&lt;/p&gt;

&lt;p&gt;Storm的一大卖点是高度的稳定性，所以往往异常处理代码量比正常逻辑代码要多很多。&lt;/p&gt;

&lt;p&gt;BTW, 看到这样一个段子：每条原始的Unix命令，都会变成一项互联网服务:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    find -&amp;gt; yahool!,
    grep-&amp;gt;Google, 
    rsync-&amp;gt;Dropbox, 
    man-&amp;gt;stack overflow, 
    MapReduce = grep|sort|uniq,
    cron-&amp;gt;ifttt，
    cp-&amp;gt;Tencent, 
    trap-&amp;gt;360, 
    wall-&amp;gt;weibo.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实&lt;code&gt;Storm&lt;/code&gt;不正是对应着&lt;code&gt;Pipe&lt;/code&gt;吗:)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>